{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d56ab114114d56e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stage 1: Import Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T14:10:56.336226100Z",
     "start_time": "2023-10-24T14:10:54.799487600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow logging (1: INFO, 2: WARNING, 3: ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # Hide any TensorFlow warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"scipy\")\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "from lxml import etree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc3a801064b9d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stage 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceeaf99c-0f7c-4383-aec9-f2f4d5a08026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T14:10:58.333090Z",
     "start_time": "2023-10-24T14:10:58.318036900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a27bd2dee1a1521",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:11:00.377167Z",
     "start_time": "2023-10-24T14:11:00.361334400Z"
    }
   },
   "outputs": [],
   "source": [
    "filePath = \"Cleaned CCMatrix v1- EN to AR Dataset.tmx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d86f2373e50d7b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:11:00.983687400Z",
     "start_time": "2023-10-24T14:11:00.923687700Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_control_characters(chunk):\n",
    "    # Remove control characters except for tab, newline, and carriage return\n",
    "    chunk = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]', '', chunk)\n",
    "    chunk = re.sub(r'\\ufffe', '', chunk)  # Remove the 0xFFFE character\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05481eb7cfba887",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE_FILE = 1024 * 1024  # 1MB\n",
    "\n",
    "with open(\"CCMatrix v1- EN to AR Dataset.tmx\", mode='r', encoding='utf-8') as f_src, \\\n",
    "        open(filePath, mode='w', encoding='utf-8') as f_dst:\n",
    "    while True:\n",
    "        chunk = f_src.read(BUFFER_SIZE_FILE)\n",
    "        if not chunk:\n",
    "            break\n",
    "        cleaned_chunk = clean_control_characters(chunk)\n",
    "        f_dst.write(cleaned_chunk)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8af487ce20d9ad3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:11:04.073543500Z",
     "start_time": "2023-10-24T14:11:04.064544500Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_tu_elements(tu):\n",
    "    ar_text = \"\"\n",
    "    en_text = \"\"\n",
    "    for tuv in tu.findall(\"tuv\"):\n",
    "        lang = tuv.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "        seg_text = tuv.findtext(\"seg\")\n",
    "        if lang == \"ar\":\n",
    "            ar_text = seg_text\n",
    "        elif lang == \"en\":\n",
    "            en_text = seg_text\n",
    "    return ar_text, en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579e5cc8a63dd33b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:18:54.780208700Z",
     "start_time": "2023-10-24T14:11:39.855263500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434.8069450855255 seconds\n",
      "Arabic: 49697322\n",
      "English: 49697322\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ar_texts = []\n",
    "en_texts = []\n",
    "\n",
    "counter = 0\n",
    "limit = 50000  # Change the number of sentences to read\n",
    "flag = False  # True, stop at limit. False, ignore limit\n",
    "\n",
    "context = etree.iterparse(filePath, events=('end',), tag='tu')\n",
    "for event, elem in context:\n",
    "    ar_text, en_text = extract_tu_elements(elem)\n",
    "    if ar_text != \"\" and en_text != \"\":\n",
    "        ar_texts.append(ar_text)\n",
    "        en_texts.append(en_text)\n",
    "        counter += 1\n",
    "    # clear the element to free up memory\n",
    "    elem.clear()\n",
    "    while elem.getprevious() is not None:\n",
    "        del elem.getparent()[0]\n",
    "    if flag and counter == limit:\n",
    "        break\n",
    "end = time.time()\n",
    "print(f\"{end - start} seconds\")\n",
    "print(\"Arabic:\", len(ar_texts))\n",
    "print(\"English:\", len(en_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500178240c5c1eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309aea77-eb47-42ea-8e82-63acaa2a34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore this if you do not have a tokenizer to load\n",
    "# Loading the English tokenizer\n",
    "with open('tokenizer_en.pkl', 'rb') as handle:\n",
    "    tokenizer_en = pickle.load(handle)\n",
    "    word_index_en = tokenizer_en.word_index\n",
    "\n",
    "# Loading the Arabic tokenizer\n",
    "with open('tokenizer_ar.pkl', 'rb') as handle:\n",
    "    tokenizer_ar = pickle.load(handle)\n",
    "    word_index_ar = tokenizer_ar.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47370023edb553b9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:43:30.602633500Z",
     "start_time": "2023-10-24T14:19:01.699311400Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer_en.fit_on_texts(en_texts)\n",
    "word_index_en = tokenizer_en.word_index\n",
    "\n",
    "tokenizer_ar = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer_ar.fit_on_texts(ar_texts)\n",
    "word_index_ar = tokenizer_ar.word_index\n",
    "#tokenizer.fit_on_texts(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142f8692-9c25-426f-8272-441641854ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T14:51:40.831607900Z",
     "start_time": "2023-10-24T14:51:34.093933300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the English tokenizer\n",
    "with open('tokenizer_en.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_en, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Saving the Arabic tokenizer\n",
    "with open('tokenizer_ar.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_ar, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef95dfac2e4f1d24",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:52:22.042249400Z",
     "start_time": "2023-10-24T14:52:22.019250700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057219\n",
      "5467127\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE_EN = len(word_index_en) + 2\n",
    "print(VOCAB_SIZE_EN)\n",
    "\n",
    "VOCAB_SIZE_AR = len(word_index_ar) + 2\n",
    "print(VOCAB_SIZE_AR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be33e5251851840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T06:06:23.400387300Z",
     "start_time": "2023-10-24T06:06:22.691058600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "START_TOKEN_EN = VOCAB_SIZE_EN - 2\n",
    "END_TOKEN_EN = VOCAB_SIZE_EN - 1\n",
    "inputs = [[START_TOKEN_EN] + tokenizer_en.texts_to_sequences([sentence])[0] + [END_TOKEN_EN] for sentence in en_texts]\n",
    "\n",
    "START_TOKEN_AR = VOCAB_SIZE_AR - 2\n",
    "END_TOKEN_AR = VOCAB_SIZE_AR - 1\n",
    "\n",
    "outputs = [[START_TOKEN_AR] + tokenizer_en.texts_to_sequences([sentence])[0] + [END_TOKEN_AR] for sentence in en_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb7e651154448e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check the tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1e78311f02513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T06:13:05.534322600Z",
     "start_time": "2023-10-24T06:13:05.527773300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(inputs[:5])\n",
    "print(outputs[:5])\n",
    "\n",
    "print(len(inputs))\n",
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e49d9552512f7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Remove long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c8ce6963fcb12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T06:14:18.245994600Z",
     "start_time": "2023-10-24T06:14:18.235219700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "indices_to_remove = [indx for indx, sent in enumerate(inputs)\n",
    "                     if len(sent) > MAX_LENGTH]\n",
    "# Remove from the last, since doing it in the normal way would fuck up the length making the indices shift by one to the left, so deleting from the right is safe\n",
    "for idx in reversed(indices_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "\n",
    "# do the same but for arabic    \n",
    "indices_to_remove = [indx for indx, sent in enumerate(outputs)\n",
    "                     if len(sent) > MAX_LENGTH]\n",
    "for idx in reversed(indices_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "\n",
    "print(len(inputs))\n",
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec364b7e38aca399",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Input/Output Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac800d51cacc095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T06:34:30.441894600Z",
     "start_time": "2023-10-24T06:34:30.341260500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, value=0,\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=MAX_LENGTH)\n",
    "\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs, value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc646a144e0b3c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T06:40:18.140893900Z",
     "start_time": "2023-10-24T06:40:16.087565200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "datasets = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "\n",
    "datasets = datasets.cache()  # Speed training, but does nothing else kek\n",
    "datasets = datasets.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "datasets = datasets.prefetch(tf.data.experimental.AUTOTUNE)  # Speed training, but does nothing else kek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eebc57023fa5aae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stage 3: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd6614a80d7e01",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761720deeaa94b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T06:54:43.765542400Z",
     "start_time": "2023-10-24T06:54:43.762813400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):  # pos is (seq_ength,1) and i is (1,d_model), hence the return \n",
    "        # pos and i are arrays\n",
    "        angles = 1 / np.power(10000., (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angles  # returns (seq_length, d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
    "                                 np.arange(d_model)[np.newaxis, :],\n",
    "                                 d_model)\n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2])  # even\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2])  # odd\n",
    "        pos_encoding = angles[np.newaxis, ...]\n",
    "        return inputs + tf.cast(pos_encoding, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5373f99339abe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14997e2e70b9283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T07:21:15.031979400Z",
     "start_time": "2023-10-24T07:21:15.021785500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    if mask is not None:\n",
    "        scaled_product += (mask * -1e9)\n",
    "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
    "\n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5b659b3a8e3c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T07:34:39.571118300Z",
     "start_time": "2023-10-24T07:34:39.530824100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, nb_projection):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.nb_projection = nb_projection\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        assert self.d_model % self.nb_projection == 0\n",
    "\n",
    "        self.d_proj = self.d_model // self.nb_projection\n",
    "\n",
    "        self.query_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "        self.value_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "    def split_proj(self, inputs, batch_size):  # inputs: (batch_size,seq_length,d_model)\n",
    "        shape = (batch_size,\n",
    "                 -1,\n",
    "                 self.nb_projection,\n",
    "                 self.d_proj)\n",
    "        splitted_inputs = tf.reshape(inputs, shape=shape)  #(batch_size, seq_length, nb_proj, d_proj)\n",
    "\n",
    "        return tf.transpose(splitted_inputs, perm=[0, 2, 1, 3])  # (batch_size, nb_proj, seq_length, d_proj)\n",
    "\n",
    "    def call(self, queries, keys, values, mask):\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "        queries = self.query_lin(queries)\n",
    "        keys = self.key_lin(keys)\n",
    "        values = self.value_lin(values)\n",
    "\n",
    "        queries = self.split_proj(queries, batch_size)\n",
    "        keys = self.split_proj(keys, batch_size)\n",
    "        values = self.split_proj(values, batch_size)\n",
    "\n",
    "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
    "\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(attention, shape=(batch_size, -1, self.d_model))\n",
    "\n",
    "        outputs_att = self.final_lin(concat_attention)\n",
    "\n",
    "        return outputs_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a73a688a54681",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553ee4885c73854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T07:47:03.063984400Z",
     "start_time": "2023-10-24T07:47:03.060985200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, FFN_units, nb_proj, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.d_model, activation='relu')\n",
    "\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, mask, training=False):\n",
    "        attention = self.multi_head_attention(inputs, inputs, inputs, mask)\n",
    "        attention = self.dropout_1(attention, training=training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "\n",
    "        outputs = self.dense_1(attention)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_2(outputs)\n",
    "        outputs = self.norm_2(outputs + attention)\n",
    "\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9875a50cf0542c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T07:58:09.218654700Z",
     "start_time": "2023-10-24T07:58:09.206654400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name='encoder'):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        self.nb_layers = nb_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        self.enc_layers = [EncoderLayer(FFN_units, nb_proj, dropout) for _ in range(nb_layers)]\n",
    "\n",
    "    def call(self, inputs, mask, training=False):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "\n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask, training)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104b7abcf33105d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb0d7674bb647a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:20:44.536813400Z",
     "start_time": "2023-10-24T10:20:44.495245700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.m_model = input_shape[-1]\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.m_model, activation='relu')\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training=False):\n",
    "        attention = self.multi_head_attention_1(inputs, inputs, inputs, mask_1)\n",
    "        attention = self.dropout_1(attention, training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "\n",
    "        attention_2 = self.multi_head_attention_2(attention,\n",
    "                                                  enc_outputs,\n",
    "                                                  enc_outputs,\n",
    "                                                  mask_2)\n",
    "\n",
    "        attention_2 = self.dropout_2(attention_2, training)\n",
    "        attention_2 = self.norm_2(attention_2 + attention)\n",
    "\n",
    "        outputs = self.dense_1(attention_2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        outputs = self.norm_3(outputs + attention_2)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595defd0d2ac9d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:20:45.557232400Z",
     "start_time": "2023-10-24T10:20:45.552699400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_projc,\n",
    "                 droupout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name='decoder'):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.nb_layers = nb_layers\n",
    "\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.post_encoding = PositionalEncoding()\n",
    "        self.dropout_1 = layers.Dropout(rate=droupout)\n",
    "\n",
    "        self.decoder_layers = [DecoderLayer(FFN_units, nb_projc, droupout) for _ in range(nb_layers)]\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.post_encoding(outputs)\n",
    "        outputs = self.dropout_1(outputs, training)\n",
    "\n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.decoder_layers[i](outputs, enc_outputs, mask_1, mask_2, training)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824002cb63581dc8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89842a5ab2476f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:20:49.592423300Z",
     "start_time": "2023-10-24T10:20:49.581357700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 vocab_size_enc,\n",
    "                 vocab_size_dec,\n",
    "                 d_model,\n",
    "                 nb_layers,\n",
    "                 FFN_units,\n",
    "                 nb_proj,\n",
    "                 dropout,\n",
    "                 name='transformer'):\n",
    "        super(Transformer, self).__init__(name=name)\n",
    "        self.encoder = Encoder(nb_layers, FFN_units, nb_proj, dropout, vocab_size_enc, d_model)\n",
    "        self.decoder = Decoder(nb_layers, FFN_units, nb_proj, dropout, vocab_size_dec, d_model)\n",
    "\n",
    "        self.last_linear = layers.Dense(units=vocab_size_dec)\n",
    "\n",
    "    def create_padding_mask(self, seq):  # seq = (batch_size, seq_length)\n",
    "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def create_look_ahead_mask(self, seq):\n",
    "        seq_len = tf.shape(seq)[1]\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        return look_ahead_mask\n",
    "\n",
    "    def call(self, enc_inputs, dec_inputs, training):\n",
    "        enc_mask = self.create_padding_mask(enc_inputs)\n",
    "        dec_mask_1 = tf.maximum(self.create_padding_mask(dec_inputs),\n",
    "                                self.create_look_ahead_mask(dec_inputs)\n",
    "                                )\n",
    "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
    "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
    "        dec_outputs = self.decoder(dec_inputs, enc_outputs, dec_mask_1, dec_mask_2, training)\n",
    "\n",
    "        outputs = self.last_linear(dec_outputs)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f93b8a27533da5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stage 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488092cb88478253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:20:50.052558300Z",
     "start_time": "2023-10-24T10:20:50.007871300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Hyper-Parameters\n",
    "D_MODEL = 256  # 512\n",
    "NB_LAYERS = 6  # 6\n",
    "FFN_UNITS = 1024  # 2048\n",
    "NB_PROJ = 8  # 8\n",
    "DROPOUT = 0.1  # 0.1\n",
    "\n",
    "transfomer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n",
    "                         vocab_size_dec=VOCAB_SIZE_AR,\n",
    "                         d_model=D_MODEL,\n",
    "                         nb_layers=NB_LAYERS,\n",
    "                         FFN_units=FFN_UNITS,\n",
    "                         nb_proj=NB_PROJ,\n",
    "                         dropout=DROPOUT,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301473076f7fd304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:20:50.329124500Z",
     "start_time": "2023-10-24T10:20:50.321428600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
    "\n",
    "\n",
    "def loss_function(target, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    loss_ = loss_object(target, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334f121e72b33c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:20:50.640914700Z",
     "start_time": "2023-10-24T10:20:50.633027Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b4fac76e0d777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:38:53.977301400Z",
     "start_time": "2023-10-24T10:38:53.966839500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./MODEL\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transfomer=transfomer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest checkpoint restored!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3446ecd440c876c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:38:58.059937600Z",
     "start_time": "2023-10-24T10:38:54.432607Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting of epoc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 15:25:33.690364: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30248960 exceeds 10% of free system memory.\n",
      "2023-10-24 15:25:34.001003: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30248960 exceeds 10% of free system memory.\n",
      "2023-10-24 15:25:34.439932: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30248960 exceeds 10% of free system memory.\n",
      "2023-10-24 15:25:34.455877: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30248960 exceeds 10% of free system memory.\n",
      "2023-10-24 15:25:34.734466: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30248960 exceeds 10% of free system memory.\n",
      "2023-10-24 15:25:34.856491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562bca775ec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-24 15:25:34.856540: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2023-10-24 15:25:34.862639: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-24 15:25:35.013679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-10-24 15:25:35.088401: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fb5c37fa440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fb5c37fa440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1 Batch 0 Loss 3.8079 Accuracy0.1209\n",
      "Epoch 1 Batch 50 Loss 4.0143 Accuracy0.1306\n",
      "Epoch 1 Batch 100 Loss 3.9553 Accuracy0.1359\n",
      "Epoch 1 Batch 150 Loss 3.9309 Accuracy0.1410\n",
      "Epoch 1 Batch 200 Loss 3.9056 Accuracy0.1462\n",
      "Epoch 1 Batch 250 Loss 3.8776 Accuracy0.1521\n",
      "Epoch 1 Batch 300 Loss 3.8464 Accuracy0.1583\n",
      "Epoch 1 Batch 350 Loss 3.8046 Accuracy0.1669\n",
      "Epoch 1 Batch 400 Loss 3.7547 Accuracy0.1762\n",
      "Epoch 1 Batch 450 Loss 3.6957 Accuracy0.1872\n",
      "Epoch 1 Batch 500 Loss 3.6272 Accuracy0.1986\n",
      "Epoch 1 Batch 550 Loss 3.5541 Accuracy0.2108\n",
      "Epoch 1 Batch 600 Loss 3.4752 Accuracy0.2231\n",
      "Epoch 1 Batch 650 Loss 3.3939 Accuracy0.2353\n",
      "Saving checkpoint for epoch 1 at ./MODEL/ckpt-2\n",
      "Time taken for 1 epoch  249.1934244632721 seconds \n",
      "Starting of epoc2\n",
      "Epoch 2 Batch 0 Loss 1.9533 Accuracy0.4046\n",
      "Epoch 2 Batch 50 Loss 1.9828 Accuracy0.4102\n",
      "Epoch 2 Batch 100 Loss 1.9128 Accuracy0.4223\n",
      "Epoch 2 Batch 150 Loss 1.8548 Accuracy0.4332\n",
      "Epoch 2 Batch 200 Loss 1.7931 Accuracy0.4435\n",
      "Epoch 2 Batch 250 Loss 1.7359 Accuracy0.4538\n",
      "Epoch 2 Batch 300 Loss 1.6808 Accuracy0.4644\n",
      "Epoch 2 Batch 350 Loss 1.6275 Accuracy0.4733\n",
      "Epoch 2 Batch 400 Loss 1.5767 Accuracy0.4820\n",
      "Epoch 2 Batch 450 Loss 1.5309 Accuracy0.4896\n",
      "Epoch 2 Batch 500 Loss 1.4870 Accuracy0.4969\n",
      "Epoch 2 Batch 550 Loss 1.4424 Accuracy0.5041\n",
      "Epoch 2 Batch 600 Loss 1.4010 Accuracy0.5110\n",
      "Epoch 2 Batch 650 Loss 1.3622 Accuracy0.5172\n",
      "Saving checkpoint for epoch 2 at ./MODEL/ckpt-3\n",
      "Time taken for 1 epoch  230.4982669353485 seconds \n",
      "Starting of epoc3\n",
      "Epoch 3 Batch 0 Loss 0.6799 Accuracy0.6192\n",
      "Epoch 3 Batch 50 Loss 0.6853 Accuracy0.5997\n",
      "Epoch 3 Batch 100 Loss 0.6779 Accuracy0.5996\n",
      "Epoch 3 Batch 150 Loss 0.6705 Accuracy0.6012\n",
      "Epoch 3 Batch 200 Loss 0.6569 Accuracy0.6042\n",
      "Epoch 3 Batch 250 Loss 0.6467 Accuracy0.6068\n",
      "Epoch 3 Batch 300 Loss 0.6334 Accuracy0.6104\n",
      "Epoch 3 Batch 350 Loss 0.6275 Accuracy0.6129\n",
      "Epoch 3 Batch 400 Loss 0.6177 Accuracy0.6155\n",
      "Epoch 3 Batch 450 Loss 0.6096 Accuracy0.6178\n",
      "Epoch 3 Batch 500 Loss 0.5994 Accuracy0.6199\n",
      "Epoch 3 Batch 550 Loss 0.5920 Accuracy0.6216\n",
      "Epoch 3 Batch 600 Loss 0.5833 Accuracy0.6232\n",
      "Epoch 3 Batch 650 Loss 0.5746 Accuracy0.6253\n",
      "Saving checkpoint for epoch 3 at ./MODEL/ckpt-4\n",
      "Time taken for 1 epoch  225.2084138393402 seconds \n",
      "Starting of epoc4\n",
      "Epoch 4 Batch 0 Loss 0.2815 Accuracy0.7007\n",
      "Epoch 4 Batch 50 Loss 0.3681 Accuracy0.6322\n",
      "Epoch 4 Batch 100 Loss 0.3657 Accuracy0.6366\n",
      "Epoch 4 Batch 150 Loss 0.3616 Accuracy0.6380\n",
      "Epoch 4 Batch 200 Loss 0.3643 Accuracy0.6409\n",
      "Epoch 4 Batch 250 Loss 0.3652 Accuracy0.6427\n",
      "Epoch 4 Batch 300 Loss 0.3625 Accuracy0.6441\n",
      "Epoch 4 Batch 350 Loss 0.3616 Accuracy0.6461\n",
      "Epoch 4 Batch 400 Loss 0.3609 Accuracy0.6470\n",
      "Epoch 4 Batch 450 Loss 0.3628 Accuracy0.6478\n",
      "Epoch 4 Batch 500 Loss 0.3629 Accuracy0.6482\n",
      "Epoch 4 Batch 550 Loss 0.3628 Accuracy0.6492\n",
      "Epoch 4 Batch 600 Loss 0.3646 Accuracy0.6498\n",
      "Epoch 4 Batch 650 Loss 0.3643 Accuracy0.6497\n",
      "Saving checkpoint for epoch 4 at ./MODEL/ckpt-5\n",
      "Time taken for 1 epoch  225.71338152885437 seconds \n",
      "Starting of epoc5\n",
      "Epoch 5 Batch 0 Loss 0.2432 Accuracy0.6390\n",
      "Epoch 5 Batch 50 Loss 0.2707 Accuracy0.6417\n",
      "Epoch 5 Batch 100 Loss 0.2726 Accuracy0.6452\n",
      "Epoch 5 Batch 150 Loss 0.2739 Accuracy0.6471\n",
      "Epoch 5 Batch 200 Loss 0.2757 Accuracy0.6492\n",
      "Epoch 5 Batch 250 Loss 0.2783 Accuracy0.6503\n",
      "Epoch 5 Batch 300 Loss 0.2811 Accuracy0.6516\n",
      "Epoch 5 Batch 350 Loss 0.2849 Accuracy0.6516\n",
      "Epoch 5 Batch 400 Loss 0.2861 Accuracy0.6534\n",
      "Epoch 5 Batch 450 Loss 0.2873 Accuracy0.6539\n",
      "Epoch 5 Batch 500 Loss 0.2897 Accuracy0.6548\n",
      "Epoch 5 Batch 550 Loss 0.2917 Accuracy0.6556\n",
      "Epoch 5 Batch 600 Loss 0.2927 Accuracy0.6566\n",
      "Epoch 5 Batch 650 Loss 0.2926 Accuracy0.6570\n",
      "Saving checkpoint for epoch 5 at ./MODEL/ckpt-6\n",
      "Time taken for 1 epoch  222.6737678050995 seconds \n",
      "Starting of epoc6\n",
      "Epoch 6 Batch 0 Loss 0.3689 Accuracy0.6308\n",
      "Epoch 6 Batch 50 Loss 0.2449 Accuracy0.6472\n",
      "Epoch 6 Batch 100 Loss 0.2392 Accuracy0.6497\n",
      "Epoch 6 Batch 150 Loss 0.2338 Accuracy0.6528\n",
      "Epoch 6 Batch 200 Loss 0.2362 Accuracy0.6552\n",
      "Epoch 6 Batch 250 Loss 0.2396 Accuracy0.6568\n",
      "Epoch 6 Batch 300 Loss 0.2433 Accuracy0.6580\n",
      "Epoch 6 Batch 350 Loss 0.2468 Accuracy0.6590\n",
      "Epoch 6 Batch 400 Loss 0.2504 Accuracy0.6600\n",
      "Epoch 6 Batch 450 Loss 0.2537 Accuracy0.6605\n",
      "Epoch 6 Batch 500 Loss 0.2552 Accuracy0.6608\n",
      "Epoch 6 Batch 550 Loss 0.2561 Accuracy0.6613\n",
      "Epoch 6 Batch 600 Loss 0.2577 Accuracy0.6619\n",
      "Epoch 6 Batch 650 Loss 0.2586 Accuracy0.6618\n",
      "Saving checkpoint for epoch 6 at ./MODEL/ckpt-7\n",
      "Time taken for 1 epoch  218.37285709381104 seconds \n",
      "Starting of epoc7\n",
      "Epoch 7 Batch 0 Loss 0.2236 Accuracy0.6456\n",
      "Epoch 7 Batch 50 Loss 0.2060 Accuracy0.6495\n",
      "Epoch 7 Batch 100 Loss 0.2072 Accuracy0.6490\n",
      "Epoch 7 Batch 150 Loss 0.2082 Accuracy0.6533\n",
      "Epoch 7 Batch 200 Loss 0.2099 Accuracy0.6567\n",
      "Epoch 7 Batch 250 Loss 0.2127 Accuracy0.6575\n",
      "Epoch 7 Batch 300 Loss 0.2154 Accuracy0.6581\n",
      "Epoch 7 Batch 350 Loss 0.2198 Accuracy0.6597\n",
      "Epoch 7 Batch 400 Loss 0.2234 Accuracy0.6614\n",
      "Epoch 7 Batch 450 Loss 0.2273 Accuracy0.6623\n",
      "Epoch 7 Batch 500 Loss 0.2304 Accuracy0.6628\n",
      "Epoch 7 Batch 550 Loss 0.2321 Accuracy0.6634\n",
      "Epoch 7 Batch 600 Loss 0.2333 Accuracy0.6640\n",
      "Epoch 7 Batch 650 Loss 0.2351 Accuracy0.6642\n",
      "Saving checkpoint for epoch 7 at ./MODEL/ckpt-8\n",
      "Time taken for 1 epoch  222.91934442520142 seconds \n",
      "Starting of epoc8\n",
      "Epoch 8 Batch 0 Loss 0.2194 Accuracy0.6776\n",
      "Epoch 8 Batch 50 Loss 0.1966 Accuracy0.6542\n",
      "Epoch 8 Batch 100 Loss 0.1996 Accuracy0.6546\n",
      "Epoch 8 Batch 150 Loss 0.2012 Accuracy0.6565\n",
      "Epoch 8 Batch 200 Loss 0.2008 Accuracy0.6588\n",
      "Epoch 8 Batch 250 Loss 0.2046 Accuracy0.6603\n",
      "Epoch 8 Batch 300 Loss 0.2075 Accuracy0.6605\n",
      "Epoch 8 Batch 350 Loss 0.2103 Accuracy0.6623\n",
      "Epoch 8 Batch 400 Loss 0.2136 Accuracy0.6633\n",
      "Epoch 8 Batch 450 Loss 0.2170 Accuracy0.6643\n",
      "Epoch 8 Batch 500 Loss 0.2194 Accuracy0.6649\n",
      "Epoch 8 Batch 550 Loss 0.2226 Accuracy0.6652\n",
      "Epoch 8 Batch 600 Loss 0.2248 Accuracy0.6655\n",
      "Epoch 8 Batch 650 Loss 0.2270 Accuracy0.6655\n",
      "Saving checkpoint for epoch 8 at ./MODEL/ckpt-9\n",
      "Time taken for 1 epoch  224.39313054084778 seconds \n",
      "Starting of epoc9\n",
      "Epoch 9 Batch 0 Loss 0.1200 Accuracy0.6390\n",
      "Epoch 9 Batch 50 Loss 0.1928 Accuracy0.6565\n",
      "Epoch 9 Batch 100 Loss 0.1858 Accuracy0.6591\n",
      "Epoch 9 Batch 150 Loss 0.1890 Accuracy0.6598\n",
      "Epoch 9 Batch 200 Loss 0.1906 Accuracy0.6620\n",
      "Epoch 9 Batch 250 Loss 0.1940 Accuracy0.6634\n",
      "Epoch 9 Batch 300 Loss 0.1982 Accuracy0.6646\n",
      "Epoch 9 Batch 350 Loss 0.2030 Accuracy0.6661\n",
      "Epoch 9 Batch 400 Loss 0.2068 Accuracy0.6662\n",
      "Epoch 9 Batch 450 Loss 0.2106 Accuracy0.6660\n",
      "Epoch 9 Batch 500 Loss 0.2144 Accuracy0.6662\n",
      "Epoch 9 Batch 550 Loss 0.2176 Accuracy0.6664\n",
      "Epoch 9 Batch 600 Loss 0.2211 Accuracy0.6663\n",
      "Epoch 9 Batch 650 Loss 0.2228 Accuracy0.6665\n",
      "Saving checkpoint for epoch 9 at ./MODEL/ckpt-10\n",
      "Time taken for 1 epoch  223.2586989402771 seconds \n",
      "Starting of epoc10\n",
      "Epoch 10 Batch 0 Loss 0.2301 Accuracy0.6299\n",
      "Epoch 10 Batch 50 Loss 0.1888 Accuracy0.6558\n",
      "Epoch 10 Batch 100 Loss 0.1915 Accuracy0.6567\n",
      "Epoch 10 Batch 150 Loss 0.1941 Accuracy0.6583\n",
      "Epoch 10 Batch 200 Loss 0.1956 Accuracy0.6597\n",
      "Epoch 10 Batch 250 Loss 0.1970 Accuracy0.6601\n",
      "Epoch 10 Batch 300 Loss 0.2010 Accuracy0.6608\n",
      "Epoch 10 Batch 350 Loss 0.2032 Accuracy0.6621\n",
      "Epoch 10 Batch 400 Loss 0.2066 Accuracy0.6640\n",
      "Epoch 10 Batch 450 Loss 0.2101 Accuracy0.6646\n",
      "Epoch 10 Batch 500 Loss 0.2126 Accuracy0.6648\n",
      "Epoch 10 Batch 550 Loss 0.2147 Accuracy0.6656\n",
      "Epoch 10 Batch 600 Loss 0.2176 Accuracy0.6662\n",
      "Epoch 10 Batch 650 Loss 0.2199 Accuracy0.6670\n",
      "Saving checkpoint for epoch 10 at ./MODEL/ckpt-11\n",
      "Time taken for 1 epoch  219.85589694976807 seconds \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Starting of epoc{epoch + 1}\")\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (enc_inputs, targets)) in enumerate(datasets):\n",
    "        dec_inputs = targets[:, :-1]\n",
    "        dec_outputs_real = targets[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = transfomer(enc_inputs, dec_inputs, True)\n",
    "            loss = loss_function(dec_outputs_real, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, transfomer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, transfomer.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(dec_outputs_real, prediction)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy{:.4f}\".format(epoch + 1, batch, train_loss.result(),\n",
    "                                                                        train_accuracy.result()))\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f\"Saving checkpoint for epoch {epoch + 1} at {ckpt_save_path}\")\n",
    "    print(f\"Time taken for 1 epoch  {time.time() - start} seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19da8eabb41a3e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:45:17.356387800Z",
     "start_time": "2023-10-24T10:45:17.307821Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    inp_sentence = [START_TOKEN_EN] + tokenizer_en.texts_to_sequences([inp_sentence])[0] + [END_TOKEN_EN]\n",
    "    enc_inputs = tf.expand_dims(inp_sentence, axis=0)\n",
    "    outputs = tf.expand_dims([START_TOKEN_AR], axis=0)\n",
    "\n",
    "    for _ in range(MAX_LENGTH):\n",
    "        predictions = transfomer(enc_inputs, outputs, False)  # (1, Seq Length, vocab_size_ar)\n",
    "        prediction = predictions[:, -1, :]\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
    "        if predicted_id == END_TOKEN_AR:\n",
    "            return tf.squeeze(outputs, axis=0)\n",
    "        predicted_id = tf.expand_dims(predicted_id, -1)  # Expand dimensions to make it [1,1]\n",
    "        outputs = tf.concat([outputs, predicted_id], axis=-1)\n",
    "    return tf.squeeze(outputs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdaa53a25e08fc29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:45:17.822320400Z",
     "start_time": "2023-10-24T10:45:17.815320800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    outputs = evaluate(sentence).numpy()\n",
    "    filtered_outputs = [i for i in outputs if i < START_TOKEN_AR]\n",
    "\n",
    "    # Decode the filtered token IDs back to text\n",
    "    decoded_text = tokenizer_ar.sequences_to_texts([filtered_outputs])[0]\n",
    "    print(f\"Input: {sentence}, Output: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1970560bf719ba15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T10:45:47.238010Z",
     "start_time": "2023-10-24T10:45:47.026962400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How Are you so bad?, Output: هنا عن هذا لكن عشر\n"
     ]
    }
   ],
   "source": [
    "translate(\"How Are you so bad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f45bb9-eeb1-46e9-8771-071b05b7cf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed80f0001cfdac5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
