{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Stage 1: Import Everything"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d56ab114114d56e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:49:56.663556400Z",
     "start_time": "2023-10-23T13:49:49.236444700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stage 2: Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0cc3a801064b9d7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      <tuv xml:lang=\"en\"><seg>Watch \u0003The Squid and the Whale now on MUBI.</seg></tuv>\n"
     ]
    }
   ],
   "source": [
    "#run this if you want to find out what causes an error, just change the index\n",
    "indexWithError = 190361\n",
    "with open(\"CCMatrix v1- EN to AR Dataset.tmx\", mode='r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == indexWithError:  # because line numbers start from 0\n",
    "            print(line)\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:17:52.039629100Z",
     "start_time": "2023-10-23T13:17:51.964058200Z"
    }
   },
   "id": "bbef3e700efabf77"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def clean_control_characters(line):\n",
    "    # Remove control characters except for tab, newline, and carriage return\n",
    "    return re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]', '', line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:17:57.236184800Z",
     "start_time": "2023-10-23T13:17:57.229142900Z"
    }
   },
   "id": "95d86f2373e50d7b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to process the file: 959.04 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open(\"CCMatrix v1- EN to AR Dataset.tmx\", mode='r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "cleaned_lines = [clean_control_characters(line) for line in lines]\n",
    "\n",
    "with open(\"CCMatrix v1- EN to AR Dataset.tmx\", mode='w', encoding='utf-8') as f:\n",
    "    f.writelines(cleaned_lines)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken to process the file: {time_taken:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:33:59.033432200Z",
     "start_time": "2023-10-23T13:17:59.790709900Z"
    }
   },
   "id": "b05481eb7cfba887"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 190362, column 36 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[1;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[0;32m~\\PycharmProjects\\EN-AR Translator\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3526\u001B[0m in \u001B[0;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0m  Cell \u001B[0;32mIn[3], line 12\u001B[0m\n    tree = ET.parse(f)\u001B[0m\n",
      "\u001B[0m  File \u001B[0;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\xml\\etree\\ElementTree.py:1218\u001B[0m in \u001B[0;35mparse\u001B[0m\n    tree.parse(source, parser)\u001B[0m\n",
      "\u001B[1;36m  File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\xml\\etree\\ElementTree.py:580\u001B[1;36m in \u001B[1;35mparse\u001B[1;36m\n\u001B[1;33m    self._root = parser._parse_whole(source)\u001B[1;36m\n",
      "\u001B[1;36m  File \u001B[1;32m<string>\u001B[1;36m\u001B[0m\n\u001B[1;31mParseError\u001B[0m\u001B[1;31m:\u001B[0m not well-formed (invalid token): line 190362, column 36\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ar_texts = []\n",
    "en_texts = []\n",
    "counter = 0\n",
    "\n",
    "# Create a dictionary for namespaces\n",
    "namespaces = {'xml': 'http://www.w3.org/XML/1998/namespace'}\n",
    "\n",
    "with open(\"CCMatrix v1- EN to AR Dataset.tmx\", mode='r', encoding='utf-8') as f:\n",
    "    # Parse the content into an XML tree\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    counter = 0\n",
    "    for tu in root.findall('.//tu'):\n",
    "        current_tu = {}\n",
    "\n",
    "        for tuv in tu.findall('tuv'):\n",
    "            lang = tuv.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "            seg_text = tuv.find('seg').text\n",
    "            if seg_text:  # Check if seg_text is not None\n",
    "                current_tu[lang] = clean_control_characters(seg_text)\n",
    "\n",
    "        if \"ar\" in current_tu and \"en\" in current_tu:\n",
    "            ar_texts.append(current_tu[\"ar\"])\n",
    "            en_texts.append(current_tu[\"en\"])\n",
    "\n",
    "        counter += 1\n",
    "        if counter == 5:\n",
    "            break\n",
    "\n",
    "# print to check results\n",
    "print(\"Arabic:\", ar_texts)\n",
    "print(\"English:\", en_texts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:50:17.809141400Z",
     "start_time": "2023-10-23T13:50:16.802216400Z"
    }
   },
   "id": "96dbadfe925d06fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=2 ** 16, oov_token='<OOV>')\n",
    "#tokenizer.fit_on_texts(data_clean)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47370023edb553b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b4e500535578b5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48bd6614a80d7e01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
